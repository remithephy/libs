{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ":@Author: Remi\n",
    ":@Date: 2023/9/13 08:21:53\n",
    ":@LastEditors: Remi\n",
    ":@LastEditTime: 2023/12/17 13:08:51\n",
    ":Description: \n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import preprocessing as pp\n",
    "import file_tool as ft\n",
    "\n",
    "path = r'D:\\20231218'\n",
    "path_list = ft.find_file(path,'.csv')\n",
    "\n",
    "filename = [os.path.basename(path_list[i])[:-4] for i in range(len(path_list))]####保留文件名\n",
    "\n",
    "\n",
    "for path_num,paths in enumerate(path_list):\n",
    "    wl,spec = ft.read_ava(paths)\n",
    "    rsd = []\n",
    "\n",
    "    spec = pp.Anomalous_spectrum_removal(spec[:,:])\n",
    "    wl = wl[:]#################################################################切片了，不切的删掉这行\n",
    "    spec_num = len(spec[0,:])\n",
    "    \n",
    "    rsd.append(pp.RSD_calculate(spec,spec_num))\n",
    "    #导入对应一个波长的所有光谱数据，平均将光谱分为n份的数量\n",
    "\n",
    "\n",
    "    ##########weighted method\n",
    "    ##############genrate slope map#########\n",
    "    ###################feather devide###########    \n",
    "    for i in range(spec_num):#calculate slope\n",
    "        \n",
    "        spec[:,i] = pp.Normalization(spec[:,i],method='total_intensity')\n",
    "        \n",
    "        single_spec = spec[:,i]\n",
    "        slope = np.int64((np.append(single_spec,single_spec[-1]) - np.insert(single_spec,0,single_spec[0]))>= 0)#eg  0123 vs 0 -1 1 1 0 ,-1 is the slope between num0&1\n",
    "        peak = np.insert(slope,0,slope[0]) - np.append(slope,slope[-1])\n",
    "        if i == 0:\n",
    "            slope_map = slope\n",
    "            peak_map = peak\n",
    "        else:\n",
    "            slope_map = np.vstack((slope_map,slope)) \n",
    "            peak_map = np.vstack((peak_map,peak)) \n",
    "            #map 1 = + while 0 = -\n",
    "    \n",
    "    slope_map[slope_map == 0] = - 1\n",
    "    peak_map = peak_map[:,1:-1].T###计算peak形状\n",
    "\n",
    "    for single_ in slope_map:###计算 arise 和 decay 形状\n",
    "        for i in range(len(single_)-1):\n",
    "            if single_[i] != single_[i+1]:\n",
    "                single_[i] = 0\n",
    "\n",
    "    scores =  (np.abs(np.sum(peak_map,axis = 1)) +  np.abs(np.sum(slope_map[:,:-1],axis = 0)))/spec_num\n",
    "    mean_spec = np.mean(spec,axis = 1)\n",
    "\n",
    "###########other process method\n",
    "    '''\n",
    "    different weighed method\n",
    "    '''\n",
    "    #weighter_spec = mean_spec * np.log((scores * (math.e - 1) + 1))\n",
    "    weighter_spec = mean_spec * scores\n",
    "\n",
    "    #slice_wl,slice_spec = pp.spec_slice([50,50],[50,50],[11544,11644],wl,spec)\n",
    "    #slice_wl = slice_wl.flatten()\n",
    "\n",
    "\n",
    "#########for save\n",
    "    if path_num == 0:\n",
    "        wl_list = np.hstack((np.array(([['wl']])).T,wl.T))\n",
    "        mean_spec_list = np.hstack((filename[path_num],mean_spec))\n",
    "    else:\n",
    "        mean_spec_list = np.vstack((mean_spec_list,np.hstack((filename[path_num],mean_spec))))\n",
    "\n",
    "#np.savetxt(path + '//' +filename[path_num]+ 'sliced.csv',np.hstack((np.array(([slice_wl])).T,slice_spec)),delimiter=',',fmt='%.04f')\n",
    "#np.savetxt(path + '//' +filename[path_num]+ 'wei.csv',np.hstack((wl,np.vstack((mean_spec,weighter_spec)).T)),delimiter=',',fmt='%.04f')\n",
    "np.savetxt(path + '//' + 'normalized.csv',np.vstack((wl_list,mean_spec_list)).T,delimiter=',',fmt = '%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ListedColormap\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mset_printoptions(precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      9\u001b[0m cmap\u001b[38;5;241m=\u001b[39mmpl\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mRdYlBu_r\u001b[38;5;66;03m#获取色条\u001b[39;00m\n\u001b[0;32m     10\u001b[0m newcolors\u001b[38;5;241m=\u001b[39mcmap(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m256\u001b[39m))\u001b[38;5;66;03m#分片操作\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(precision = 6)\n",
    "\n",
    "cmap=mpl.cm.RdYlBu_r#获取色条\n",
    "newcolors=cmap(np.linspace(0,1,256))#分片操作\n",
    "newcmap=ListedColormap(newcolors[100:])#只取100之后的颜色列表，前面的舍去\n",
    "\n",
    "peak_list = [779.898,852.075]##############peak position\n",
    "tol = 1#算峰面积的容差\n",
    "conc = []\n",
    "\n",
    "##################path##########################\n",
    "filename = r'D:\\20231218\\normalized.csv'#file position\n",
    "savepath = r'D:\\20221218'\n",
    "##################load#########################\n",
    "\n",
    "wl,spec=ft.Load_MultiSpec(filename)\n",
    "wl = wl[1:]\n",
    "spec = spec[1:,:]\n",
    "#meanspec = np.mean(spec,axis = 1)############while variable no_grad use mean spec , otherwise chose max spec \n",
    "maxspec = np.max(spec,axis = 1)\n",
    "\n",
    "p,m,peak_list = pp.Peak_integrate(wl,maxspec,peak_list,tol)\n",
    "\n",
    "##################calculate#####################\n",
    "for i in range(len(spec[0])):\n",
    "    for j in range(len(peak_list)):#pm wavelength\n",
    "\n",
    "        slice_cache = spec[peak_list[j] - m[j]:peak_list[j] + p[j],i]\n",
    "        slice_square = (p[j] + m[j] + 1) * (slice_cache[0] + slice_cache[-1])/2\n",
    "        if j == 0:\n",
    "            slice_ = slice_cache.sum(axis=0) - slice_square\n",
    "        else:\n",
    "            slice_ = np.vstack((slice_,(slice_cache.sum(axis=0) - slice_square)))\n",
    "\n",
    "        if i == 0:\n",
    "            conc.append(wl[peak_list[j]])\n",
    "\n",
    "    if i == 0:\n",
    "        slice_sample = slice_   \n",
    "    else: \n",
    "        slice_sample = np.hstack((slice_sample,slice_))\n",
    "\n",
    "###################save#####################################\n",
    "\n",
    "#np.savetxt(savepath +'\\\\' + 'square.csv',np.hstack((np.array([conc]).T,slice_sample)).T,delimiter=',',fmt='%.04f')  \n",
    "\n",
    "###################plot#####################################\n",
    "\n",
    "for j in range(len(peak_list)):\n",
    "    sns_spec = spec[:][peak_list[j] - m[j]:peak_list[j] + p[j],:]\n",
    "    sns_wl = wl_cache = wl[peak_list[j] - m[j]:peak_list[j] + p[j]]\n",
    "\n",
    "##################减阴影\n",
    "    for i in range(len(sns_spec[0,:])):\n",
    "        slope = (sns_spec[:,i][0] - sns_spec[:,i][-1])/(sns_wl[0] - sns_wl[-1])\n",
    "        bias = sns_spec[:,i][0] - slope * sns_wl[0]\n",
    "        sns_spec[:,i] = sns_spec[:,i] - (sns_wl * slope + bias)\n",
    "\n",
    "##################展区间\n",
    "    for i in range(len(sns_spec[0][:]) - 1):\n",
    "        sns_wl = np.column_stack((sns_wl,wl_cache))\n",
    "\n",
    "    sns_spec = sns_spec.flatten()\n",
    "    sns_wl = sns_wl.flatten()\n",
    "    data = np.column_stack((sns_wl, sns_spec))\n",
    "    df = pd.DataFrame(data, columns=['wl', 'int'])\n",
    "    sns.relplot(x=\"wl\", y=\"int\", kind=\"line\", data=df,ci = \"sd\")\n",
    "    sns.relplot(x=\"wl\", y=\"int\", kind=\"line\", data=df)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
