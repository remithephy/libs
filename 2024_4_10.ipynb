{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在计算：D:\\20240412\\10\\10.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\11\\11.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\12\\12.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\13\\13.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\14\\14.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\15\\15.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\16\\16.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\17\\17.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\18\\18.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\19\\19.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\20\\20.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\6\\6.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\7\\7.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\8\\8.csv method = total_intensity\n",
      "正在计算：D:\\20240412\\9\\9.csv method = total_intensity\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import preprocessing as pp\n",
    "import file_tool as ft\n",
    "\n",
    "path = r'D:\\20240412'\n",
    "path_list = ft.find_file(path,'.csv')\n",
    "\n",
    "filename = [os.path.basename(path_list[i])[:-4] for i in range(len(path_list))]####保留文件名\n",
    "\n",
    "#################default_iter##############\n",
    "aim_peak = []\n",
    "scores = 1\n",
    "#####ctrl ku  ctrl kc\n",
    "\n",
    "################################内标用到的峰#######################################\n",
    "wl,spec = ft.read_ava(path_list[0])\n",
    "maxspec = np.max(spec,axis = 1)\n",
    "int_peak = [742.361,744.322,746.852]##氢线656.302      氮线742.361,744.322,746.852     氧777.257\n",
    "peak_para = pp.Peak_integrate(wl,maxspec,int_peak)\n",
    "\n",
    "\n",
    "for path_num,paths in enumerate(path_list):\n",
    "    method = 'total_intensity'#'total_intensity' 'internal_standard'\n",
    "    print('正在计算：' + paths,'method = ' + method)\n",
    "    wl,spec = ft.read_ava(paths)\n",
    "    rsd = []\n",
    "\n",
    "    channel = 0###########10381最后一个通道，8284倒数第二个spec[8284:,:],进行切片###########\n",
    "\n",
    "    spec = pp.Anomalous_spectrum_removal(spec[channel:,:])\n",
    "    wl = wl[channel:]\n",
    "    spec_num = len(spec[0,:])\n",
    "    \n",
    "\n",
    "\n",
    "    for wave in range(len(spec[:,0])):    \n",
    "        rsd.append(pp.RSD_calculate(spec[wave,:],spec_num))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #cun nm spec\n",
    "\n",
    "    for i in range(spec_num):#calculate slope\n",
    "        \n",
    "        spec[:,i] = pp.Normalization(spec[:,i],method,peak_para) \n",
    "        \n",
    "#########################slope 计算部分#########################################  \n",
    "        single_spec = spec[:,i]\n",
    "        slope = np.int64((np.append(single_spec,single_spec[-1]) - np.insert(single_spec,0,single_spec[0]))>= 0)#eg  0123 vs 0 -1 1 1 0 ,-1 is the slope between num0&1\n",
    "        peak = np.insert(slope,0,slope[0]) - np.append(slope,slope[-1])\n",
    "        if i == 0:\n",
    "            slope_map = slope\n",
    "            peak_map = peak\n",
    "        else:\n",
    "            slope_map = np.vstack((slope_map,slope)) \n",
    "            peak_map = np.vstack((peak_map,peak)) \n",
    "            #map 1 = + while 0 = -\n",
    "    \n",
    "    slope_map[slope_map == 0] = - 1\n",
    "    peak_map = peak_map[:,1:-1].T###计算peak形状\n",
    "\n",
    "    for single_ in slope_map:###计算 arise 和 decay 形状\n",
    "        for i in range(len(single_)-1):\n",
    "            if single_[i] != single_[i+1]:\n",
    "                single_[i] = 0\n",
    "\n",
    "    scores =  (np.abs(np.sum(peak_map,axis = 1)) +  np.abs(np.sum(slope_map[:,:-1],axis = 0)))/spec_num\n",
    "\n",
    "###################################################################################\n",
    "    for i in range(spec_num):\n",
    "        spec[:,i] = pp.Normalization(spec[:,i],method,peak_para) ###shifou gui yihua\n",
    "###########cun#####\n",
    "    wei_spec = (spec.T * scores).T\n",
    "    wei_mean_spec = np.hstack((filename[path_num],np.mean(wei_spec,axis = 1))).reshape(-1)\n",
    "    mean_spec = np.hstack((filename[path_num],np.mean(spec,axis = 1))).reshape(-1)\n",
    "    rsd = np.hstack((filename[path_num],rsd)).reshape(-1)\n",
    "\n",
    "    if path_num == 0:\n",
    "        rsd_list = rsd\n",
    "        mean_list = mean_spec\n",
    "        wei_mean_list = wei_mean_spec\n",
    "    else:\n",
    "        rsd_list = np.vstack((rsd_list,rsd))\n",
    "        mean_list = np.vstack((mean_list,mean_spec))\n",
    "        wei_mean_list = np.vstack((wei_mean_list,wei_mean_spec))\n",
    "\n",
    "    np.savetxt(path + '//' +filename[path_num]+ 'nm.csv',np.hstack((wl,spec)),delimiter=',',fmt = '%s')\n",
    "    np.savetxt(path + '//' +filename[path_num]+ 'wei.csv',np.hstack((wl,wei_spec)),delimiter=',',fmt = '%s')\n",
    "\n",
    "wl = np.hstack(('wl',wl.reshape(-1))).reshape(-1)\n",
    "\n",
    "np.savetxt(path + '//' + path[-4:] + 'rsd.csv',np.vstack((np.array([wl]),rsd_list)).T,delimiter=',',fmt = '%s')\n",
    "np.savetxt(path + '//' + path[-4:] + 'mean.csv',np.vstack((np.array([wl]),mean_list)).T,delimiter=',',fmt = '%s')\n",
    "np.savetxt(path + '//' + path[-4:] + 'wei_mean.csv',np.vstack((np.array([wl]),wei_mean_list)).T,delimiter=',',fmt = '%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
