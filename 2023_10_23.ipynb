{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ":@Author: Remi\n",
    ":@Date: 2023/9/13 08:21:53\n",
    ":@LastEditors: Remi\n",
    ":@LastEditTime: 2023/10/19 20:07:26\n",
    ":Description: \n",
    "'''\n",
    "import numpy as np\n",
    "import preprocessing as pp\n",
    "import file_tool as ft\n",
    "import math\n",
    "\n",
    "path = r'D:\\20231017\\origin'\n",
    "path_list = ft.find_file(path,'.csv')\n",
    "name_list = ['1000','100','10','500','50','300','30']\n",
    "n = 0\n",
    "\n",
    "for paths in path_list:\n",
    "    wl,spec = ft.read_ava(paths)\n",
    "    slice = 0\n",
    "    spec = pp.Anomalous_spectrum_removal(spec[slice:,:])\n",
    "    wl = wl[slice:]#################################################################切片了，不切的删掉这行\n",
    "    spec_num = len(spec[0,:])\n",
    "    rsd = np.array([pp.RSD_calculate(spec[wave,:],int(spec_num/10)) for wave in range(len(wl))])\n",
    "    origin_spec = spec\n",
    "   \n",
    "    ##############genrate slope map#########\n",
    "    ###################feather devide###########    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(spec_num):#calculate slope\n",
    "        origin_mean_spec = np.mean(spec,axis = 1)\n",
    "        spec[:,i] = pp.Normalization(spec[:,i],method='total_intensity')\n",
    "        \n",
    "        single_spec = spec[:,i]\n",
    "        slope = np.int64((np.append(single_spec,single_spec[-1]) - np.insert(single_spec,0,single_spec[0]))>= 0)#eg  0123 vs 0 -1 1 1 0 ,-1 is the slope between num0&1\n",
    "        peak = np.insert(slope,0,slope[0]) - np.append(slope,slope[-1])\n",
    "        if i == 0:\n",
    "            slope_map = slope\n",
    "            peak_map = peak\n",
    "        else:\n",
    "            slope_map = np.vstack((slope_map,slope)) \n",
    "            peak_map = np.vstack((peak_map,peak)) \n",
    "            #map 1 = + while 0 = -\n",
    "    \n",
    "    slope_map[slope_map == 0] = - 1\n",
    "    peak_map = peak_map[:,1:-1].T###计算peak形状\n",
    "\n",
    "    for single_ in slope_map:###计算 arise 和 decay 形状\n",
    "        for i in range(len(single_)-1):\n",
    "            if single_[i] != single_[i+1]:\n",
    "                single_[i] = 0\n",
    "\n",
    "    scores =  (np.abs(np.sum(peak_map,axis = 1)) +  np.abs(np.sum(slope_map[:,:-1],axis = 0)))/spec_num\n",
    "    mean_spec = np.mean(spec,axis = 1)\n",
    "\n",
    "\n",
    "    '''\n",
    "    different weighed method\n",
    "    '''\n",
    "    #weighter_spec = mean_spec * np.log((scores * (math.e - 1) + 1))\n",
    "    weighter_spec = mean_spec * scores\n",
    "    \n",
    "    ######################这部分先不用了###################\n",
    "    #slice_wl,slice_spec = pp.spec_slice([50,50],[50,50],[11544,11644],wl,spec)\n",
    "    #slice_wl = slice_wl.flatten()\n",
    "\n",
    "    #np.savetxt(path + '//' + name_list[n] + 'rsd.csv',np.hstack((wl,np.array(([rsd])).T)),delimiter=',',fmt='%.04f')\n",
    "    np.savetxt(path + '//' + name_list[n] + 'origin_mean.csv',np.hstack((wl,np.array(([origin_mean_spec])).T)),delimiter=',',fmt='%.04f')\n",
    "    #np.savetxt(path + '//' + name_list[n] + 'normalized.csv',np.hstack((wl,spec)),delimiter=',',fmt='%.04f')\n",
    "    #np.savetxt(path + '//' + name_list[n] + 'origin.csv',np.hstack((wl,origin_spec)),delimiter=',',fmt='%.04f')\n",
    "    np.savetxt(path + '//' + name_list[n] + 'weighted.csv',np.hstack((wl,np.vstack((mean_spec,weighter_spec)).T)),delimiter=',',fmt='%.04f')\n",
    "    n = n+1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
