{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessing as prep\n",
    "from model import perturbation\n",
    "from model import BPNN as Predictor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "\n",
    "# wl_path = r'D:\\20240412\\wl.csv'\n",
    "# select_path = r'D:\\20240412\\0412mean.csv'\n",
    "\n",
    "# select = pd.read_csv(select_path,header=None).values\n",
    "# raw_wl = pd.read_csv(wl_path,header=None).values.astype(np.float32)[12200-2048:12200]\n",
    "\n",
    "# mean_spec = select[1:,1:]\n",
    "# mean_spec = mean_spec[12200-2048:12200,:].T.astype(float)\n",
    "# mean_lab = select[0,1:].astype(float)\n",
    "# SKB = SelectKBest(f_regression, k=10)\n",
    "# select_feat = SKB.fit_transform(mean_spec, mean_lab.ravel())\n",
    "# index_feat = SKB.get_support()\n",
    "# np.savetxt(r'D:/20240412/select_wl.csv',np.vstack((raw_wl[index_feat].reshape(-1),np.where(index_feat)[0])).T,delimiter=',',fmt='%s')\n",
    "\n",
    "path = r'D:\\20240412\\Rb_analysis\\all.csv'\n",
    "label_path = r'D:\\20240412\\Rb_analysis\\alllab.csv'\n",
    "wl_path = r'D:\\20240412\\Rb_analysis\\wl.csv'\n",
    "save_path = r'D:\\20240412\\Rb_analysis\\bpnn'\n",
    "\n",
    "# super iter\n",
    "num_feat = 10\n",
    "random_seed = 2024  \n",
    "batch_size = 128\n",
    "lr = 5e-4\n",
    "num_epochs = 300\n",
    "step_epoch = 10\n",
    "new_feat_size = 300\n",
    "mean_times = 50\n",
    "new_feat = []\n",
    "new_lab = []\n",
    "\n",
    "\n",
    "######### read raw data ####################\n",
    "\n",
    "raw_feat = pd.read_csv(path,header=None).values.astype(np.float32)[:,12195-4096:12195]\n",
    "raw_label = pd.read_csv(label_path,header=None).values.astype(np.float32)\n",
    "raw_wl = pd.read_csv(wl_path,header=None).values.astype(np.float32)[12201-4096:12201]\n",
    "\n",
    "######### make new feat ####################\n",
    "unique_lab = np.unique(raw_label)\n",
    "for labs in unique_lab:\n",
    "    index = np.isin(raw_label,labs).reshape(-1)\n",
    "    unique_feat = raw_feat[index,:]\n",
    "    for _ in range(new_feat_size):\n",
    "        new_feat.append(np.mean(unique_feat[sample(range(0,len(unique_feat[:,0]-1)),mean_times),:],axis = 0))\n",
    "        new_lab.append(labs)\n",
    "\n",
    "new_feat = np.array(new_feat)\n",
    "new_lab = np.array(new_lab).reshape(-1,1)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# new_feat = scaler.fit_transform(new_feat.T).T\n",
    "\n",
    "# 取测试集\n",
    "unique_lab = np.unique(new_lab)\n",
    "\n",
    "select_lab = unique_lab[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "wl_path = r'D:\\20240412\\Rb_analysis\\wl.csv'\n",
    "select_path = r'D:\\20240412\\Rb_analysis\\0412wei_mean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "select = pd.read_csv(select_path,header=None).values\n",
    "raw_wl = pd.read_csv(wl_path,header=None).values.astype(np.float32)[12200-4096:12200]\n",
    "mean_spec = select[1:,1:]\n",
    "mean_spec = mean_spec[12200-4096:12200,:].T.astype(float)\n",
    "mean_lab = select[0,1:].astype(float)\n",
    "SKB = SelectKBest(f_regression, k=10)\n",
    "select_feat = SKB.fit_transform(mean_spec, mean_lab.ravel())\n",
    "index_feat = SKB.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x200ade97730>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(raw_wl,mean_spec[0,:])\n",
    "plt.scatter(raw_wl[index_feat],mean_spec[0,index_feat],c = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.savetxt(r'D:/20240412/select_wl.csv',np.vstack((raw_wl[index_feat].reshape(-1),np.where(index_feat)[0])).T,delimiter=',',fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "norm_feat = []\n",
    "\n",
    "\n",
    "test_index = np.isin(new_lab,select_lab).reshape(-1)#-600 500 -1 50 \n",
    "\n",
    "# # normalization\n",
    "# feat_scaler = MinMaxScaler()\n",
    "# lab_scaler = MinMaxScaler()\n",
    "\n",
    "# for spec in range(len(new_feat[:,0])):\n",
    "#     norm_feat.append(prep.Normalization(new_feat[spec,:]) )\n",
    "# norm_feat = np.array(norm_feat) * 1000\n",
    "norm_feat = new_feat * 1000\n",
    "# norm_lab = lab_scaler.fit_transform(raw_label)\n",
    "\n",
    "#buyong scaler\n",
    "\n",
    "test_feat = norm_feat[test_index,:]\n",
    "test_label = new_lab[test_index]\n",
    "train_feat = norm_feat[~test_index,:]\n",
    "train_label = new_lab[~test_index]\n",
    "\n",
    "# random seeding\n",
    "\n",
    "np.random.seed(random_seed)  \n",
    "random_index = [i for i in range(len(train_label))]\n",
    "np.random.shuffle(random_index)\n",
    "\n",
    "train_feat = train_feat[random_index,:]\n",
    "train_label = train_label[random_index]\n",
    "\n",
    "\n",
    "# # import select\n",
    "index_feat = pd.read_csv(r'D:\\20240412\\select_wl.csv',header=None).values[:,1].astype(int)\n",
    "\n",
    "\n",
    "train_feat = train_feat[:, index_feat]\n",
    "test_feat = test_feat[:, index_feat]\n",
    "\n",
    "select_wl = raw_wl[index_feat]\n",
    "\n",
    "# split train and test\n",
    "# x_train,x_test,y_train,y_test = train_test_split(\n",
    "#     norm_feat,norm_lab, test_size=0.2,shuffle = False)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_feat,test_feat,train_label,test_label\n",
    "\n",
    "\n",
    "\n",
    "train_data = torch.tensor(x_train, dtype=torch.float32)\n",
    "train_label = torch.tensor(y_train, dtype=torch.float32)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(train_data, train_label), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = torch.tensor(x_test, dtype=torch.float32)\n",
    "test_label = torch.tensor(y_test, dtype=torch.float32)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(test_data, test_label), batch_size=batch_size, shuffle=True)\n",
    "'''remember to set shuffle to False'''\n",
    "\n",
    "\n",
    "# parameter define\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"Using GPU !\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "logdir = os.getcwd()\n",
    "\n",
    "model = Predictor(num_feat,7,5,1)\n",
    "perturb = perturbation(num_feat)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "perturb_optimizer = torch.optim.Adam(perturb.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# variable define\n",
    "all_sigma = []\n",
    "all_net = []\n",
    "mse_loss = []\n",
    "train_loss = []\n",
    "all_train_rmse = []\n",
    "all_train_loss = []\n",
    "all_test_rmse = []\n",
    "all_test_mae = []\n",
    "all_test_loss = []\n",
    "train_pre_lab = []\n",
    "test_pre_lab = []\n",
    "\n",
    "\n",
    "## 模型训练\n",
    "model.to(device)\n",
    "\n",
    "    \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(train_dataloader, total=len(train_dataloader))#loop 是使用 tqdm 创建的一个进度条，用于可视化每个轮次内部的循环进度。\n",
    "    \n",
    "    for x, y in loop:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        loop.set_description('epoch: [%d/%d]' % (epoch, num_epochs))\n",
    "    \n",
    "    if epoch % step_epoch == 0: # 每step_epoch次epoch存一次数据\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            sum_train_loss = 0\n",
    "            sum_test_loss = 0\n",
    "            sum_train_rmse = 0\n",
    "            sum_test_rmse = 0\n",
    "            sum_test_mae = 0\n",
    "            for x, y in train_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                preds = model(x)\n",
    "\n",
    "                # 评估指标\n",
    "                # y_denormalized = lab_scaler.inverse_transform(y.cpu())\n",
    "                # preds_denormalized = lab_scaler.inverse_transform(preds.cpu())\n",
    "                y_denormalized = y\n",
    "                preds_denormalized = preds\n",
    "\n",
    "                # 计算损失\n",
    "                loss = torch.zeros_like(y_denormalized)  # 创建一个与 y 相同形状的张量来存储损失\n",
    "                abs_loss_mask = (y_denormalized == 0.0)  # 布尔掩码，用于标记 y 中等于零的部分\n",
    "\n",
    "                # 对等于零的部分使用绝对值损失\n",
    "                loss[abs_loss_mask] = torch.abs(preds_denormalized[abs_loss_mask] - y_denormalized[abs_loss_mask])\n",
    "                # 对不等于零的部分使用均方误差损失\n",
    "                mse_loss_mask = ~abs_loss_mask  # 取反，用于标记 y 中不等于零的部分\n",
    "                loss[mse_loss_mask] = torch.mean(torch.abs(preds_denormalized[mse_loss_mask] - y_denormalized[mse_loss_mask])) \\\n",
    "                    / y_denormalized[mse_loss_mask]\n",
    "                train_loss = loss.mean()\n",
    "                sum_train_loss = sum_train_loss + train_loss\n",
    "\n",
    "                train_rmse = (np.sqrt(((preds_denormalized - y_denormalized).cpu() ** 2).mean())) # 数据存到cpu\n",
    "                sum_train_rmse = sum_train_rmse + train_rmse\n",
    "\n",
    "            for x_t, y_t in test_dataloader:\n",
    "                x_t = x_t.to(device)\n",
    "                y_t = y_t.to(device)\n",
    "                preds = model(x_t)\n",
    "\n",
    "                # 评估指标\n",
    "                # y_denormalized = lab_scaler.inverse_transform(y_t.cpu())\n",
    "                # preds_denormalized = lab_scaler.inverse_transform(preds.cpu())\n",
    "                y_denormalized = y_t\n",
    "                preds_denormalized = preds\n",
    "\n",
    "                # 计算损失\n",
    "                loss = torch.zeros_like(y_denormalized)  # 创建一个与 y 相同形状的张量来存储损失\n",
    "                abs_loss_mask = (y_denormalized == 0.0)  # 布尔掩码，用于标记 y 中等于零的部分\n",
    "                # 对等于零的部分使用绝对值损失\n",
    "                loss[abs_loss_mask] = torch.abs(preds_denormalized[abs_loss_mask] - y_denormalized[abs_loss_mask])\n",
    "                # 对不等于零的部分使用均方误差损失\n",
    "                mse_loss_mask = ~abs_loss_mask  # 取反，用于标记 y 中不等于零的部分\n",
    "                loss[mse_loss_mask] = torch.mean(torch.abs(preds_denormalized[mse_loss_mask] - y_denormalized[mse_loss_mask])) \\\n",
    "                    / y_denormalized[mse_loss_mask]\n",
    "                test_loss = loss.mean()\n",
    "                sum_test_loss = sum_test_loss + test_loss\n",
    "\n",
    "                test_rmse = (np.sqrt(((preds_denormalized - y_denormalized).cpu() ** 2).mean()))\n",
    "                sum_test_rmse = sum_test_rmse + test_rmse\n",
    "\n",
    "                mae = np.absolute((preds_denormalized - y_denormalized).cpu()).mean()\n",
    "                sum_test_mae = sum_test_mae + mae\n",
    "\n",
    "            sum_train_loss = sum_train_loss.cpu().detach().numpy()#数据存到cpu= 直接用.item()也行\n",
    "            sum_test_loss = sum_test_loss.cpu().detach().numpy()\n",
    "            \n",
    "            all_train_loss.append(sum_train_loss / len(train_dataloader))\n",
    "            all_test_loss.append(sum_test_loss / len(test_dataloader))\n",
    "            all_train_rmse.append(sum_train_rmse / len(train_dataloader))\n",
    "            all_test_rmse.append(sum_test_rmse / len(test_dataloader))\n",
    "            all_test_mae.append(sum_test_mae / len(test_dataloader))\n",
    "            all_net.append(model)\n",
    "\n",
    "            model.train()\n",
    "\n",
    "\n",
    "\n",
    "# best epoch\n",
    "sum_loss = [(all_train_loss[i] + all_test_loss[i]) for i in range(len(all_train_loss))]\n",
    "best_epoch = sum_loss.index(min(sum_loss))\n",
    "\n",
    "#    print('best_epoch=%d' % best_epoch*step_epoch)\n",
    "if best_epoch == len(all_net):\n",
    "    best_net = all_net[best_epoch-1]\n",
    "else:\n",
    "    best_net = all_net[best_epoch]\n",
    "\n",
    "# save\n",
    "# 所有参数 \n",
    "all_train_loss1 = np.array(all_train_loss[best_epoch]).reshape(-1,1)\n",
    "all_test_loss1 = np.array(all_test_loss[best_epoch]).reshape(-1,1)\n",
    "all_train_rmse1 = np.array(all_train_rmse[best_epoch]).reshape(-1,1)\n",
    "all_test_rmse1 = np.array(all_test_rmse[best_epoch]).reshape(-1,1)\n",
    "all_test_mae1 = np.array(all_test_mae[best_epoch]).reshape(-1,1)\n",
    "\n",
    "name_result = np.array(['all_train_loss','all_test_loss','all_train_rmse','all_test_rmse','all_test_mae']).reshape(-1,1).T\n",
    "exp_result = np.hstack((all_train_loss1,all_test_loss1,all_train_rmse1,all_test_rmse1,all_test_mae1))\n",
    "result = np.vstack((name_result,exp_result))\n",
    "\n",
    "torch.save(best_net,save_path + '//' + str(select_lab) + 'best_net.pth')\n",
    "np.savetxt(save_path + '//' + str(select_lab) + 'result.csv',result,delimiter=',',fmt='%s')\n",
    "\n",
    "# perturbation train\n",
    "\n",
    "# best_net.cpu()\n",
    "# best_net.eval()\n",
    "\n",
    "# perturb.cpu()\n",
    "# another_epoch = int(num_epochs)\n",
    "\n",
    "# test_dataloader = torch.utils.data.DataLoader(\n",
    "#     torch.utils.data.TensorDataset(test_data, test_label), batch_size=32, shuffle=False)\n",
    "\n",
    "# for epochs in range(another_epoch):\n",
    "#     loop = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "#     for x, y in loop:\n",
    "#         x = x.cpu()\n",
    "#         pp,pm,sigma = perturb(x)\n",
    "#         sigma = sigma.cpu().detach()#记得换个位置存\n",
    "#         p = best_net(x)\n",
    "#         pp = best_net(pp)\n",
    "#         pm = best_net(pm)\n",
    "#         pp = torch.abs(pp - p)\n",
    "#         pm = torch.abs(pm - p)\n",
    "#         const = torch.full([pp.size()[0],1],torch.max(p).item())\n",
    "#         const_0 = torch.full([pp.size()[0],1],torch.min(p).item())\n",
    "\n",
    "#         l1 = criterion(pp,const_0)\n",
    "#         l2 = criterion(pm,const)\n",
    "#         l3 = criterion(sigma,torch.zeros(num_feat))\n",
    "\n",
    "#         loss = l1 + l2 + l3\n",
    "\n",
    "\n",
    "#         perturb_optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "\n",
    "#         perturb_optimizer.step()\n",
    "        \n",
    "# #        loop.set_description('epoch: [%d/%d]' % (epoch, another_epoch))\n",
    "\n",
    "#     if epochs % step_epoch == 0: # 每step_epoch次epoch存一次数据\n",
    "#         save_sigma = sigma.clone().numpy()\n",
    "#         all_sigma.append(save_sigma)\n",
    "        \n",
    "# np.savetxt(save_path + '//' + str(select_lab) + 'sigma.csv',all_sigma,delimiter=',',fmt='%s')\n",
    "\n",
    "# # draw\n",
    "\n",
    "cutoff = 0\n",
    "plt.figure(1)\n",
    "plt.plot(all_train_loss[cutoff:], label='train_loss')\n",
    "plt.plot(all_test_loss[cutoff:], label='test_loss')\n",
    "plt.xlabel(\"epochs(10 epoch)\")\n",
    "plt.ylabel(\"all_loss(a.u.)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(all_train_rmse[cutoff:], label='train_rmse')\n",
    "plt.plot(all_test_rmse[cutoff:], label='test_rmse')\n",
    "plt.xlabel(\"epochs(10 epoch)\")\n",
    "plt.ylabel(\"all_rmse_loss(a.u.)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(all_test_mae[cutoff:], label='mae')\n",
    "plt.xlabel(\"epochs(10 epoch)\")\n",
    "plt.ylabel(\"all_test_mae(a.u.)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4)\n",
    "x = y = [0,1000]\n",
    "plt.plot(x,y)\n",
    "\n",
    "best_net.cpu()\n",
    "best_net.eval()\n",
    "\n",
    "\n",
    "# plt.scatter(lab_scaler.inverse_transform(train_label), \n",
    "#             lab_scaler.inverse_transform(best_net(train_data).detach().numpy()),\n",
    "#             label=\"train set\",c = 'r')\n",
    "# plt.scatter(lab_scaler.inverse_transform(test_label), \n",
    "#             lab_scaler.inverse_transform(best_net(test_data).detach().numpy()),\n",
    "#                 label=\"test set\",c = 'b')\n",
    "plt.scatter(train_label, \n",
    "            best_net(train_data.to(device).cpu()).cpu().detach().numpy(),\n",
    "            label=\"train set\",c = 'r')\n",
    "plt.scatter(test_label, \n",
    "            best_net(test_data.to(device).cpu()).cpu().detach().numpy(),\n",
    "                label=\"test set\",c = 'b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_label, \n",
    "            best_net(train_data.to(device).cpu()).cpu().detach().numpy(),\n",
    "            label=\"train set\",c = 'r')\n",
    "plt.scatter(test_label, \n",
    "            best_net(test_data.to(device).cpu()).cpu().detach().numpy(),\n",
    "                label=\"test set\",c = 'r')\n",
    "x = y = [0,1000]\n",
    "plt.plot(x,y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_label, \n",
    "            best_net(train_data.to(device).cpu()).cpu().detach().numpy(),\n",
    "            label=\"train set\",c = 'r')\n",
    "plt.scatter(test_label, \n",
    "            best_net(test_data.to(device).cpu()).cpu().detach().numpy(),\n",
    "                label=\"test set\",c = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# save_Y = np.hstack((np.vstack((train_label,test_label)),\n",
    "#                np.vstack((best_net(train_data.to(device).cpu()).cpu().detach().numpy(),\n",
    "#                           best_net(test_data.to(device).cpu()).cpu().detach().numpy()))))\n",
    "\n",
    "# np.savetxt(save_path + '//' + 'Y_predict_all.csv',save_Y,delimiter=',',fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zjy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
